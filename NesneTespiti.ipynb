{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EĞİTİMİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CIFAR-10 dataset from keras' datasets\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Import this PyPlot to visualize images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Print the shapes of training and testing set\n",
    "print(\"X_train.shape =\", X_train.shape, \"Y_train.shape =\", Y_train.shape)\n",
    "print(\"X_test.shape =\", X_test.shape, \"Y_test.shape =\", Y_test.shape)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "# show random images from training set\n",
    "cols = 8 # Number of columns\n",
    "rows = 4 # Number of rows\n",
    "\n",
    "fig = plt.figure(figsize=(2 * cols, 2 * rows))\n",
    "\n",
    "# Add subplot for each random image\n",
    "for col in range(cols):\n",
    "    for row in range(rows):\n",
    "        random_index = np.random.randint(0, len(Y_train)) # Pick a random index for sampling the image\n",
    "        ax = fig.add_subplot(rows, cols, col * rows + row + 1) # Add a sub-plot at (row, col)\n",
    "        ax.grid(False) # Get rid of the grids\n",
    "        ax.axis(\"off\") # Get rid of the axis\n",
    "        ax.imshow(X_train[random_index, :]) # Show random image\n",
    "        ax.set_title(CIFAR10_CLASSES[Y_train[random_index][0]]) # Set title of the sub-plot\n",
    "plt.show() # Show the image\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(\"TensorFlow's version is\", tf.__version__)\n",
    "print(\"Keras' version is\", tf.keras.__version__)\n",
    "\n",
    "\n",
    "# Normalize training and testing pixel values\n",
    "X_train_normalized = X_train / 255 - 0.5\n",
    "X_test_normalized = X_test / 255 - 0.5\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train_coded = tf.keras.utils.to_categorical(Y_train, NUM_CLASSES)\n",
    "Y_test_coded = tf.keras.utils.to_categorical(Y_test, NUM_CLASSES)\n",
    "\n",
    "# import necessary building blocks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Dropout(rate=0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Dropout(rate=0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=256))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(units=10))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # img_width, img_height, img_num_channels = 32, 32, 3\n",
    "    # input_shape = (img_width, img_height, img_num_channels)\n",
    "    \n",
    "    # model = Sequential()\n",
    "    # model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Flatten())\n",
    "    # model.add(Dense(256, activation='relu'))\n",
    "    # model.add(Dense(128, activation='relu'))\n",
    "    # model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# describe model\n",
    "s = tf.keras.backend.clear_session()\n",
    "model = make_model()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "num_folds = 5\n",
    "\n",
    "# FOLD SKORLARINI TUTMAK İÇİN MATRİS TANIMLAMA\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "history_acc = []\n",
    "history_val_acc = []\n",
    "history_loss = []\n",
    "history_val_loss = []\n",
    "\n",
    "s = tf.keras.backend.clear_session()  # clear default graph\n",
    "# don't call K.set_learning_phase() !!! (otherwise will enable dropout in train/test simultaneously)\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # we train 10-way classification\n",
    "    optimizer=tf.keras.optimizers.Adamax(lr=INIT_LR),  # for SGD\n",
    "    metrics=['accuracy']  # report accuracy during training\n",
    ")\n",
    "\n",
    "\n",
    "# scheduler of learning rate (decay with epochs)\n",
    "def lr_scheduler(epoch):\n",
    "    return INIT_LR * 0.9 ** epoch\n",
    "\n",
    "\n",
    "\n",
    "# callback for printing of actual learning rate used by optimizer\n",
    "class LrHistory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(\"Learning rate:\", tf.keras.backend.get_value(model.optimizer.lr))\n",
    "# # K FOLD ÇAPRAZ DOĞRULAMA\n",
    "# fold_no = 1\n",
    "# folds = list(KFold(n_splits=num_folds, shuffle=True, random_state=42).split(X_train_normalized, Y_train_coded))\n",
    "# for idx, (train_idx, val_idx) in enumerate(folds):\n",
    "  \n",
    "#   print('----------------------------------------------------------------')\n",
    "#   print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "#   X_train_cv = X_train_normalized[train_idx]\n",
    "#   y_train_cv = Y_train_coded[train_idx]\n",
    "\n",
    "#   # Validation data\n",
    "#   X_valid_cv = X_train_normalized[val_idx]\n",
    "#   y_valid_cv = Y_train_coded[val_idx]\n",
    "\n",
    "\n",
    "\n",
    "#   # fit model\n",
    "#   history = model.fit(\n",
    "#       X_train_cv, y_train_cv,  # prepared data\n",
    "#       batch_size=BATCH_SIZE,\n",
    "#       epochs=EPOCHS,\n",
    "#       callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler), \n",
    "#                 LrHistory()],\n",
    "#       validation_data=(X_valid_cv, y_valid_cv),\n",
    "#       shuffle=True,\n",
    "#       verbose=1,\n",
    "#       initial_epoch=0\n",
    "#   )\n",
    "\n",
    "#   for i in history.history['accuracy']:\n",
    "#     history_acc.append(i)\n",
    "    \n",
    "#   for i in history.history['val_accuracy']:\n",
    "#     history_val_acc.append(i)  \n",
    "\n",
    "#   for i in history.history['loss']:\n",
    "#     history_loss.append(i)\n",
    "\n",
    "#   for i in history.history['val_loss']:\n",
    "#     history_val_loss.append(i)\n",
    " \n",
    "\n",
    "\n",
    "#   # GENELLEME METRİKLERİ OLUŞTURMA\n",
    "#   scores = model.evaluate(X_train_normalized[val_idx], Y_train_coded[val_idx], verbose=0)\n",
    "#   print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "#   acc_per_fold.append(scores[1] * 100)\n",
    "#   loss_per_fold.append(scores[0])\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "#   # FOLD DEĞERİ ARTTIRMA\n",
    "#   fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "# # K FOLD SONRASI GENEL METRİKLERİN DEĞERLENDİRİLMESİ\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Score per fold')\n",
    "# for i in range(0, len(acc_per_fold)):\n",
    "#   print('------------------------------------------------------------------------')\n",
    "#   print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Average scores for all folds:')\n",
    "# print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "# print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "# print('------------------------------------------------------------------------')\n",
    "\n",
    "# fit model without kfold\n",
    "history = model.fit(\n",
    "    X_train_normalized, Y_train_coded,  # prepared data\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler), \n",
    "               LrHistory()],\n",
    "    validation_data=(X_test_normalized, Y_test_coded),\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    initial_epoch=0\n",
    ")\n",
    "scores = model.evaluate(X_train_normalized, Y_train_coded, verbose=0)\n",
    "print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "def save_model(model):# serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model_weigths.h5\")\n",
    "    model.save(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "save_model(model)\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    from tensorflow.keras.models import model_from_json\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model2.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "# #  plot kfold\n",
    "# plt.plot(history_acc)\n",
    "# plt.plot(history_val_acc)\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history_loss)\n",
    "# plt.plot(history_val_loss)\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plot without kfold\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# make test predictions\n",
    "Y_pred_test = model.predict(X_test_normalized) # Predict probability of image belonging to a class, for each class\n",
    "Y_pred_test_classes = np.argmax(Y_pred_test, axis=1) # Class with highest probability from predicted probabilities\n",
    "Y_test_classes = np.argmax(Y_test_coded, axis=1) # Actual class\n",
    "Y_pred_test_max_probas = np.max(Y_pred_test, axis=1) # Highest probability\n",
    "\n",
    "\n",
    "# confusion matrix and accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.imshow(confusion_matrix(Y_test_classes, Y_pred_test_classes))\n",
    "plt.xticks(np.arange(10), CIFAR10_CLASSES, rotation=45, fontsize=12)\n",
    "plt.yticks(np.arange(10), CIFAR10_CLASSES, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(\"Test accuracy:\", accuracy_score(Y_test_classes, Y_pred_test_classes))\n",
    "\n",
    "\n",
    "\n",
    "# inspect preditions\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(Y_test))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(X_test[random_index, :])\n",
    "        pred_label = CIFAR10_CLASSES[Y_pred_test_classes[random_index]]\n",
    "        pred_proba = Y_pred_test_max_probas[random_index]\n",
    "        true_label = CIFAR10_CLASSES[Y_test[random_index][0]]\n",
    "        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
    "               pred_label, pred_proba, true_label\n",
    "        ))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaydedilen .h5 modeli yükleme ve resim ile tahmin etme ve modelin katmanlarını gösterme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import keras.utils.vis_utils\n",
    "from importlib import reload\n",
    "reload(keras.utils.vis_utils)\n",
    "\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# model.summary()\n",
    "img = tensorflow.keras.preprocessing.image.load_img('deer.jpg', target_size=(32,32))\n",
    "\n",
    "X =  tensorflow.keras.preprocessing.image.img_to_array(img)\n",
    "X = np.expand_dims(X, axis=0)\n",
    "X /= 255\n",
    "images = np.vstack([X])\n",
    "val = model.predict(images)\n",
    "print('val', val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaydedilen .h5 modelini tflite çevirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tflite_convert \\\n",
    "  --keras_model_file=/content/model.h5\\\n",
    "  --output_file=tfmodel.tflite"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
